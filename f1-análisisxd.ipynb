{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355db1c5",
   "metadata": {},
   "source": [
    "## Modelo de datos - 1er Entregable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db89a0",
   "metadata": {},
   "source": [
    "Rosario Juan Francisco 201907394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32494fd6",
   "metadata": {},
   "source": [
    "### LIBRERIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f889c53",
   "metadata": {},
   "source": [
    "Para realizar las tablas importaremos la siguientes librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94597023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json \n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdfb77c",
   "metadata": {},
   "source": [
    "### SEASON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5657ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://ergast.com/api/f1/seasons.json?limit=1000'\n",
    "response = requests.get(url)\n",
    "content=json.loads(response.content)\n",
    "seasons = {'season':[],\n",
    "        'url':[]}\n",
    "for item in content['MRData']['SeasonTable']['Seasons']:\n",
    "    seasons['season'].append(int(item['season']))\n",
    "    seasons['url'].append(item['url'])   \n",
    "pd.DataFrame(seasons).to_csv('seasons.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73efd930",
   "metadata": {},
   "outputs": [],
   "source": [
    "UltimaTemporada = np.max(seasons['season'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8107186",
   "metadata": {},
   "source": [
    "### RACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0675e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "races = {'season':[],\n",
    "        'round':[],\n",
    "        'raceName':[],\n",
    "        'circuitId':[],\n",
    "        'lat':[],\n",
    "        'long':[],\n",
    "        'country':[],\n",
    "        'date':[],\n",
    "        'url':[], \n",
    "        'raceId':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54907b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in list(range(2010,UltimaTemporada+1)):\n",
    "    url = 'http://ergast.com/api/f1/{}.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for item in content['MRData']['RaceTable']['Races']: \n",
    "        races['season'].append(int(item['season']))\n",
    "        races['round'].append(int(item['round']))\n",
    "        races['raceName'].append(item['raceName'])\n",
    "        races['circuitId'].append(item['Circuit']['circuitId'])\n",
    "        races['lat'].append(item['Circuit']['Location']['lat'])\n",
    "        races['long'].append(item['Circuit']['Location']['long'])\n",
    "        races['country'].append(item['Circuit']['Location']['country'])\n",
    "        races['date'].append(item['date'])\n",
    "        races['url'].append(item['url'])\n",
    "        races['raceId'].append(content['MRData']['RaceTable']['Races'][0]['raceName'])\n",
    "        \n",
    "        \n",
    "    for item in content['MRData']['RaceTable']['Races']: \n",
    "        races['season'].append(int(item['season']))\n",
    "        races['round'].append(int(item['round']))\n",
    "        races['raceName'].append(item['raceName'])\n",
    "        races['circuitId'].append(item['Circuit']['circuitId'])\n",
    "        races['lat'].append(item['Circuit']['Location']['lat'])\n",
    "        races['long'].append(item['Circuit']['Location']['long'])\n",
    "        races['country'].append(item['Circuit']['Location']['country'])\n",
    "        races['date'].append(item['date'])\n",
    "        races['url'].append(item['url'])\n",
    "        races['raceId'].append(content['MRData']['RaceTable']['Races'][1]['raceName'])\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b87848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(races).to_csv('races.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a3ead",
   "metadata": {},
   "source": [
    "### DRIVERS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8d94c",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'drivers.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a5c00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers= {'driverId':[],\n",
    "         'givenName':[],\n",
    "         'familyName':[],\n",
    "         'dateOfBirth':[],\n",
    "         'nationality':[],\n",
    "         'url':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c18cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in list(range(2010,2023)):\n",
    "    url = 'http://ergast.com/api/f1/{}/drivers.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for item in content['MRData']['DriverTable']['Drivers']:\n",
    "        drivers['driverId'].append(item['driverId'])\n",
    "        drivers['givenName'].append(item['givenName'])\n",
    "        drivers['familyName'].append(item['familyName'])\n",
    "        drivers['dateOfBirth'].append(item['dateOfBirth'])\n",
    "        drivers['nationality'].append(item['nationality'])\n",
    "        drivers['url'].append(item['url'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee86ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(drivers).to_csv('drivers.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1b824",
   "metadata": {},
   "source": [
    "### CONSTRUCTORS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4ef88",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'constructors.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0918d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructors={'constructorId':[],\n",
    "             'name':[],\n",
    "              'nationality':[],\n",
    "             'url':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c8e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in list(range(2010,2023)):\n",
    "    url = 'http://ergast.com/api/f1/{}/constructors.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for item in content['MRData']['ConstructorTable']['Constructors']:\n",
    "        constructors['constructorId'].append(item['constructorId'])\n",
    "        constructors['name'].append(item['name'])\n",
    "        constructors['nationality'].append(item['nationality'])\n",
    "        constructors['url'].append(item['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e0ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(constructors).to_csv('constructors.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5f31c",
   "metadata": {},
   "source": [
    "###  CIRCUITS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36892c9e",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'circuits.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5092108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits={'circuitId':[],\n",
    "         'circuitName':[],\n",
    "        'lat':[],\n",
    "        'long':[],\n",
    "        'locality':[],\n",
    "        'country':[],\n",
    "         'url':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49347125",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in list(range(2010,2023)):\n",
    "    url = 'http://ergast.com/api/f1/{}/circuits.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for item in content['MRData']['CircuitTable']['Circuits']:\n",
    "        \n",
    "        circuits['circuitId'].append(item['circuitId'])\n",
    "        circuits['circuitName'].append(item['circuitName'])\n",
    "        circuits['lat'].append(item['Location']['lat'])\n",
    "        circuits['long'].append(item['Location']['long'])\n",
    "        circuits['locality'].append(item['Location']['locality'])\n",
    "        circuits['country'].append(item['Location']['country'])\n",
    "        circuits['url'].append(item['url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f95447",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(circuits).to_csv('circuits.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f592a90",
   "metadata": {},
   "source": [
    "### QUALIFYING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222a21d",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'qualifying.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6cc7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying={'raceId':[],\n",
    "           'driverId':[],\n",
    "           'constructorId':[],\n",
    "           'number':[],\n",
    "           'position':[], \n",
    "           'Q1':[],\n",
    "           'Q2':[],\n",
    "           'Q3':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5511853",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010,2023):\n",
    "    url='http://ergast.com/api/f1/{}/qualifying.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for item in content['MRData']['RaceTable']['Races'][0]['QualifyingResults']:\n",
    "        qualifying['raceId'].append(content['MRData']['RaceTable']['Races'][0]['raceName'])\n",
    "        qualifying['driverId'].append(item['Driver']['driverId'])\n",
    "        qualifying['constructorId'].append(item['Constructor']['constructorId'])\n",
    "        qualifying['number'].append(int(item['number']))\n",
    "        qualifying['position'].append(int(item['position']))\n",
    "        try:\n",
    "            qualifying['Q1'].append(item['Q1'])\n",
    "        except:\n",
    "            qualifying['Q1'].append(None)\n",
    "        try:\n",
    "            qualifying['Q2'].append(item['Q2'])\n",
    "        except:\n",
    "            qualifying['Q2'].append(None)\n",
    "        try:\n",
    "            qualifying['Q3'].append(item['Q3'])\n",
    "        except:\n",
    "            qualifying['Q3'].append(None)\n",
    "    for item in content['MRData']['RaceTable']['Races'][1]['QualifyingResults']:\n",
    "        qualifying['raceId'].append(content['MRData']['RaceTable']['Races'][1]['raceName'])\n",
    "        qualifying['driverId'].append(item['Driver']['driverId'])\n",
    "        qualifying['constructorId'].append(item['Constructor']['constructorId'])\n",
    "        qualifying['number'].append(int(item['number']))\n",
    "        qualifying['position'].append(int(item['position']))\n",
    "        try:\n",
    "            qualifying['Q1'].append(item['Q1'])\n",
    "        except:\n",
    "            qualifying['Q1'].append(None)\n",
    "        try:\n",
    "            qualifying['Q2'].append(item['Q2'])\n",
    "        except:\n",
    "            qualifying['Q2'].append(None)\n",
    "        try:\n",
    "            qualifying['Q3'].append(item['Q3'])\n",
    "        except:\n",
    "            qualifying['Q3'].append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9d4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(qualifying).to_csv('qualifying.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48016db",
   "metadata": {},
   "source": [
    "## SEGUNDO ENTREGABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b6150",
   "metadata": {},
   "source": [
    "### SprintResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f312d8e",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'sprintresults.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2021 a 2022, ya que la API son los unicos a√±os en que nos proporciona datos, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e3afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sprintresults={'raceId':[],\n",
    "           'driverId':[],\n",
    "           'constructorId':[],\n",
    "           'number':[],\n",
    "           'position':[], \n",
    "           'grid':[],\n",
    "           'positionText':[],\n",
    "           'points':[],\n",
    "           'laps':[],\n",
    "           'time':[], \n",
    "           'millis':[],\n",
    "            'Fastestlap':[],\n",
    "            'Fastlaptime':[],\n",
    "            'status':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0046ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2021,2023):\n",
    "    url= 'http://ergast.com/api/f1/{}/sprint.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for item in content['MRData']['RaceTable']['Races'][0]['SprintResults']:\n",
    "        \n",
    "        sprintresults['raceId'].append(content['MRData']['RaceTable']['Races'][0]['raceName'])\n",
    "        sprintresults['driverId'].append(item['Driver']['driverId'])\n",
    "        sprintresults['constructorId'].append(item['Constructor']['constructorId'])\n",
    "        sprintresults['number'].append(int(item['number']))\n",
    "        sprintresults['position'].append(int(item['position']))\n",
    "        sprintresults['grid'].append(int(item['grid']))\n",
    "        sprintresults['positionText'].append(item['positionText'])\n",
    "        sprintresults['points'].append(int(item['points']))\n",
    "        sprintresults['laps'].append(int(item['laps']))\n",
    "        sprintresults['status'].append(item['status'])\n",
    "        try:\n",
    "            sprintresults['millis'].append(item['Time']['millis'])\n",
    "        except:\n",
    "             sprintresults['millis'].append(None)\n",
    "        try:\n",
    "            sprintresults['time'].append(item['Time']['time'])\n",
    "        except:\n",
    "            sprintresults['time'].append(None)\n",
    "        try:\n",
    "            sprintresults['Fastestlap'].append(item['FastestLap']['lap'])\n",
    "        except:\n",
    "            sprintresults['Fastestlap'].append(None)\n",
    "        try:\n",
    "            sprintresults['Fastlaptime'].append(item['FastestLap']['Time']['time'])\n",
    "        except:\n",
    "            sprintresults['Fastlaptime'].append(None)\n",
    "            \n",
    "    for item in content['MRData']['RaceTable']['Races'][1]['SprintResults']:\n",
    "        sprintresults['raceId'].append(content['MRData']['RaceTable']['Races'][1]['raceName'])\n",
    "        sprintresults['driverId'].append(item['Driver']['driverId'])\n",
    "        sprintresults['constructorId'].append(item['Constructor']['constructorId'])\n",
    "        sprintresults['number'].append(int(item['number']))\n",
    "        sprintresults['position'].append(int(item['position']))\n",
    "        sprintresults['grid'].append(int(item['grid']))\n",
    "        sprintresults['positionText'].append(item['positionText'])\n",
    "        sprintresults['points'].append(int(item['points']))\n",
    "        sprintresults['laps'].append(int(item['laps']))\n",
    "        sprintresults['status'].append(item['status'])\n",
    "        try:\n",
    "            sprintresults['millis'].append(item['Time']['millis'])\n",
    "        except:\n",
    "             sprintresults['millis'].append(None)\n",
    "        try:\n",
    "            sprintresults['time'].append(item['Time']['time'])\n",
    "        except:\n",
    "            sprintresults['time'].append(None)\n",
    "        try:\n",
    "            sprintresults['Fastestlap'].append(item['FastestLap']['lap'])\n",
    "        except:\n",
    "            sprintresults['Fastestlap'].append(None)\n",
    "        try:\n",
    "            sprintresults['Fastlaptime'].append(item['FastestLap']['Time']['time'])\n",
    "        except:\n",
    "            sprintresults['Fastlaptime'].append(None)\n",
    "            \n",
    " \n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cba7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sprintresults).to_csv('sprintresults.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee55355",
   "metadata": {},
   "source": [
    "### Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5bb4da",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'status.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94766d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "status={'statusId':[],\n",
    "       'status':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a126787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010,2023):\n",
    "    url ='http://ergast.com/api/f1/{}/status.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for  item in content['MRData']['StatusTable']['Status']:\n",
    "        status['statusId'].append(item['statusId'])\n",
    "        status['status'].append(item['status'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a7b3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(status).to_csv('status.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff37c12",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3ed3c",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'results.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16201389",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={'raceId':[],\n",
    "        'driverId':[],\n",
    "        'constructorId':[],\n",
    "        'number':[],\n",
    "        'position':[], \n",
    "        'grid':[],\n",
    "        'positionText':[],\n",
    "        'points':[],\n",
    "        'laps':[],\n",
    "         'status':[],\n",
    "         'millis':[],\n",
    "        'time':[], \n",
    "        'Fastestlap':[],\n",
    "        'Fastlaptime':[],\n",
    "        'Fastlaspeed':[],\n",
    "          'rank':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a3c7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010,2023):\n",
    "    url= 'http://ergast.com/api/f1/{}/results.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for item in content['MRData']['RaceTable']['Races'][0]['Results']:\n",
    "        \n",
    "        results['raceId'].append(content['MRData']['RaceTable']['Races'][0]['raceName'])\n",
    "        results['driverId'].append(item['Driver']['driverId'])\n",
    "        results['constructorId'].append(item['Constructor']['constructorId'])\n",
    "        results['number'].append(int(item['number']))\n",
    "        results['position'].append(int(item['position']))\n",
    "        results['grid'].append(int(item['grid']))\n",
    "        results['positionText'].append(item['positionText'])\n",
    "        results['points'].append(int(item['points']))\n",
    "        results['laps'].append(int(item['laps']))\n",
    "        results['status'].append(item['status'])\n",
    "        try:\n",
    "            results['millis'].append(item['Time']['millis'])\n",
    "        except:\n",
    "             results['millis'].append(None)\n",
    "        try:\n",
    "            results['time'].append(item['Time']['time'])\n",
    "        except:\n",
    "            results['time'].append(None)\n",
    "        try:\n",
    "            results['Fastestlap'].append(item['FastestLap']['lap'])\n",
    "        except:\n",
    "            results['Fastestlap'].append(None)\n",
    "        try:\n",
    "            results['Fastlaptime'].append(item['FastestLap']['Time']['time'])\n",
    "        except:\n",
    "            results['Fastlaptime'].append(None)\n",
    "        try:\n",
    "            results['Fastlaspeed'].append(item['FastestLap']['AverageSpeed']['speed'])\n",
    "        except:\n",
    "            results['Fastlaspeed'].append(None)\n",
    "        try:\n",
    "            results['rank'].append(item['FastestLap']['rank'])\n",
    "        except:\n",
    "            results['rank'].append(None)\n",
    "            \n",
    "    for item in content['MRData']['RaceTable']['Races'][1]['Results']:\n",
    "        results['raceId'].append(content['MRData']['RaceTable']['Races'][1]['raceName'])\n",
    "        results['driverId'].append(item['Driver']['driverId'])\n",
    "        results['constructorId'].append(item['Constructor']['constructorId'])\n",
    "        results['number'].append(int(item['number']))\n",
    "        results['position'].append(int(item['position']))\n",
    "        results['grid'].append(int(item['grid']))\n",
    "        results['positionText'].append(item['positionText'])\n",
    "        results['points'].append(int(item['points']))\n",
    "        results['laps'].append(int(item['laps']))\n",
    "        results['status'].append(item['status'])\n",
    "        try:\n",
    "            results['millis'].append(item['Time']['millis'])\n",
    "        except:\n",
    "             results['millis'].append(None)\n",
    "        try:\n",
    "            results['time'].append(item['Time']['time'])\n",
    "        except:\n",
    "            results['time'].append(None)\n",
    "        try:\n",
    "            results['Fastestlap'].append(item['FastestLap']['lap'])\n",
    "        except:\n",
    "            results['Fastestlap'].append(None)\n",
    "        try:\n",
    "            results['Fastlaptime'].append(item['FastestLap']['Time']['time'])\n",
    "        except:\n",
    "            results['Fastlaptime'].append(None)\n",
    "        try:\n",
    "            results['Fastlaspeed'].append(item['FastestLap']['AverageSpeed']['speed'])\n",
    "        except:\n",
    "            results['Fastlaspeed'].append(None)\n",
    "        try:\n",
    "            results['rank'].append(item['FastestLap']['rank'])\n",
    "        except:\n",
    "            results['rank'].append(None)\n",
    "\n",
    "\n",
    "            \n",
    " \n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1727257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1df695",
   "metadata": {},
   "source": [
    "### PitStops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668877d",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'results.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46bf13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitstops={'raceId':[],\n",
    "          'driverId':[],\n",
    "          'stop':[],\n",
    "         'lap':[],\n",
    "          'time':[],\n",
    "        'duration':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b4a102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2011,2023):\n",
    "    url ='http://ergast.com/api/f1/{}/5/pitstops.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for  item in content['MRData']['RaceTable']['Races'][0]['PitStops']:\n",
    "        pitstops['raceId'].append(content['MRData']['RaceTable']['Races'][0]['raceName'])\n",
    "        pitstops['driverId'].append(item['driverId'])\n",
    "        pitstops['lap'].append(item['lap'])\n",
    "        pitstops['stop'].append(item['stop'])\n",
    "        pitstops['time'].append(item['time'])\n",
    "        pitstops['duration'].append(item['duration'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "890e6795",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pitstops).to_csv('pitstops.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b82e89",
   "metadata": {},
   "source": [
    "## TERCER ENTREGABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad830da7",
   "metadata": {},
   "source": [
    "### LapTimes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7bed9",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'laptimes.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26f0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptimes={'raceId':[],\n",
    "          'driverId':[],\n",
    "         'position':[],\n",
    "          'time':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1515beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010,2023):\n",
    "    url = 'http://ergast.com/api/f1/{}/5/laps/1.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for  item in content['MRData']['RaceTable']['Races'][0]['Laps'][0]['Timings']:\n",
    "        laptimes['raceId'].append(content['MRData']['RaceTable']['Races'][0]['raceName'])\n",
    "        laptimes['driverId'].append(item['driverId'])\n",
    "        laptimes['position'].append(item['position'])\n",
    "        laptimes['time'].append(item['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0dfa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(laptimes).to_csv('laptimes.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d3ca4",
   "metadata": {},
   "source": [
    "### DriverStandings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a78b6",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'driverstandings.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b75e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "driverstandings={'driverId':[],\n",
    "        'points':[],\n",
    "        'positions':[],\n",
    "        'positionText':[],\n",
    "        'wins':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3534c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010,2023):\n",
    "    url = 'http://ergast.com/api/f1/{}/driverStandings.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for  item in content['MRData']['StandingsTable'][ 'StandingsLists'][0]['DriverStandings']:\n",
    "        driverstandings['driverId'].append(item['Driver']['driverId'])\n",
    "        driverstandings['points'].append(item['points'])\n",
    "        driverstandings['positions'].append(item['position'])\n",
    "        driverstandings['positionText'].append(item['positionText'])\n",
    "        driverstandings['wins'].append(item['wins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c30536e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(driverstandings).to_csv('driverstandings.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf21eb",
   "metadata": {},
   "source": [
    "### ConstructorStandings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94547f4",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'constructorstandings.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96871c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructorstandings={'constructorId':[],\n",
    "        'points':[],\n",
    "        'positions':[],\n",
    "        'positionText':[],\n",
    "        'wins':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea6cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010,2023):\n",
    "    url = 'http://ergast.com/api/f1/{}/constructorStandings.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for  item in content['MRData']['StandingsTable'][ 'StandingsLists'][0]['ConstructorStandings']:\n",
    "        constructorstandings['constructorId'].append(item['Constructor']['constructorId'])\n",
    "        constructorstandings['points'].append(item['points'])\n",
    "        constructorstandings['positions'].append(item['position'])\n",
    "        constructorstandings['positionText'].append(item['positionText'])\n",
    "        constructorstandings['wins'].append(item['wins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b359b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(constructorstandings).to_csv('constructorstandings.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69575ac",
   "metadata": {},
   "source": [
    "### ConstructorResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6dec27",
   "metadata": {},
   "source": [
    "Realizaremos el archivo 'constructoresults.csv', para ello crearemos las listas que guardaran lo datos y realizaremos un ciclo for para obtener todos los datos de 2010 a 2022, por lo que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a355de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructoresults={'raceId':[],\n",
    "        'constructorId':[],\n",
    "        'points':[],\n",
    "        'status':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd29bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010,2023):\n",
    "    url= 'http://ergast.com/api/f1/{}/results.json'\n",
    "    response = requests.get(url.format(year))\n",
    "    content=json.loads(response.content)\n",
    "    \n",
    "    for item in content['MRData']['RaceTable']['Races'][0]['Results']:\n",
    "        constructoresults['raceId'].append(content['MRData']['RaceTable']['Races'][0]['raceName'])\n",
    "        constructoresults['constructorId'].append(item['Constructor']['constructorId'])\n",
    "        constructoresults['points'].append(int(item['points']))\n",
    "        constructoresults['status'].append(item['status'])\n",
    "    for item in content['MRData']['RaceTable']['Races'][1]['Results']:\n",
    "        constructoresults['raceId'].append(content['MRData']['RaceTable']['Races'][1]['raceName'])\n",
    "        constructoresults['constructorId'].append(item['Constructor']['constructorId'])\n",
    "        constructoresults['points'].append(int(item['points']))\n",
    "        constructoresults['status'].append(item['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc715a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(constructoresults).to_csv('constructoresults.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
